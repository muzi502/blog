---
title: ubuntu 1804 ä½¿ç”¨ kubeadm éƒ¨ç½² kubernetes
date: 2019-05-16
categories: æŠ€æœ¯
slug:
tag:
  - kubeadm
  - kubernetes
  - k8s
copyright: true
comment: true
---

æ³¨æ„: è¿™ä¸ªéƒ¨ç½²åœ¨äº† digital ocean çš„ VPS ä¸Šï¼Œå›½å†…çš„æœºå™¨éœ€è¦ä»£ç†ã€‚

## 1.ä¸»æœºè¦æ±‚

0.ç¡¬ä»¶è¦æ±‚ 2CPU 2GB RAM

1.ä¸´æ—¶å…³é—­ swap `swapoff -a`

2.æ‰“å¼€bridge-nf-call-iptables

```bash
cat > /etc/sysctl.d/99-kubernetes-cri.conf <<EOF
net.bridge.bridge-nf-call-iptables  = 1
enet.ipv4.ip_forward                = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF
sysctl --system
```

3.åŠ è½½ br_netfilter å†…æ ¸æ¨¡å—ï¼Œå®‰è£… docker åä¼šé»˜è®¤å¼€å¯

```bash
modprobe br_netfilter
lsmod | grep br_netfilter
```

4.ä¸´æ—¶å…³é—­ä¸€ä¸‹SELinuxï¼Œæ€ä¹ˆå…³é—­çš„ï¼Ÿï¼Ÿè²Œä¼¼æˆ‘çš„ digital ocean Ubuntu18.04 æ²¡æœ‰å®‰è£…SELinuxğŸ¤”

åœ¨ç½‘ä¸Šæ‰¾äº†ä¸€ç¯‡æ–‡ç« ä¸´æ—¶å…³é—­SELinuxçš„[turn-off-selinux](https://www.revsys.com/writings/quicktips/turn-off-selinux.html)

```bash
Test if SELinux is running
You can test to see if SELinux is currently enabled with the following command:

selinuxenabled && echo enabled || echo disabled
Turning off SELinux temporarily
Disabling SELinux temporarily is the easiest way to determine if the problem you are experiencing is related to your SELinux settings. To turn it off, you will need to become the root users on your system and execute the following command:

echo 0 > /sys/fs/selinux/enforce
This temporarily turns off SELinux until it is either re-enabled or the system is rebooted. To turn it back on you simply execute this command:

echo 1 > /sys/fs/selinux/enforce
As you can see from these commands what you are doing is setting the file /selinux/enforce to either '1' or '0' to denote 'true' and 'false'.
```

5.VPSéœ€è¦åœ¨å›½å¤–æˆ–ä»£ç†ï¼Œå› ä¸ºéœ€è¦ä¸‹è½½gcrä¸Šçš„é•œåƒã€‚å›½å†…ç”¨æˆ·å¯ä»¥è€ƒè™‘è£…ä¸ªè½¯è·¯ç”±ç„¶åè®¾ç½®ä¸ºæ—è·¯ç½‘å…³ï¼Œè¿™æ ·èƒ½é€æ˜ä»£ç†ï¼Œåªéœ€è¦ä¿®æ”¹éƒ¨ç½²æœºå™¨çš„ç½‘å…³ä¸ºè½¯è·¯ç”±å³å¯ã€‚ä¹Ÿå¯ä»¥åœ¨éƒ¨ç½²æœºå™¨ä¸Šå®‰è£…ä»£ç†ï¼Œä¸è¿‡æ¯”è¾ƒéº»çƒ¦å’Œå‘ã€‚è¿˜æ˜¯è½¯è·¯ç”±ã€æ—è·¯ç½‘å…³ã€é€æ˜ä»£ç†ä¸‰è¿æ–¹ä¾¿ğŸ˜‚ã€‚

----

## 2.å®‰è£…Dockeræˆ–å…¶ä»–å®¹å™¨è¿è¡Œæ—¶

å®˜æ–¹æ–‡æ¡£å†™äº†å»ºè®®å®‰è£…18.06.2ï¼Œå…¶ä»–ç‰ˆæœ¬çš„dockeræ”¯æŒçš„ä¸å¤ªå¥½
On each of your machines, install Docker. Version 18.06.2 is recommended, but 1.11, 1.12, 1.13, 17.03 and 18.09 are known to work as well. Keep track of the latest verified Docker version in the Kubernetes release notes.

### 1.ä½¿ç”¨kuberneteså®˜æ–¹å»ºè®®çš„å®‰è£…æ–¹å¼ğŸ˜‚

```bash
## Set up the repository:
### Install packages to allow apt to use a repository over HTTPS
apt-get update && apt-get install apt-transport-https ca-certificates curl software-properties-common

### Add Dockerâ€™s official GPG key
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -

### Add Docker apt repository.
add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"

## Install Docker CE.
apt-get update && apt-get install docker-ce=18.06.2~ce~3-0~ubuntu
```

### 2.ä¿®æ”¹ä¸€ä¸‹Dockerçš„daemon.jsonæ–‡ä»¶

åœ¨è¿™é‡Œéœ€è¦æŠŠ `native.cgroupdriver=` ä¿®æ”¹ä¸º systemdï¼Œé»˜è®¤çš„æ˜¯ dockerã€‚

```bash
cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
EOF
```

ä¸ä¿®æ”¹çš„è¯åé¢åˆå§‹åŒ–çš„æ—¶å€™ä¼šwarningğŸ˜‚

```bash
[WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/
```

æœ€åå°†dockeråŠ å…¥å¼€æœºè‡ªå¯ï¼Œå¹¶é‡å¯ä¸€ä¸‹docker

```bash
mkdir -p /etc/systemd/system/docker.service.d
systemctl daemon-reload
systemctl restart docker
```

3.(å¯é€‰)CRI-O å®¹å™¨è¿è¡Œæ—¶

```bash
#Prerequisites
modprobe overlay
modprobe br_netfilter

# Setup required sysctl params, these persist across reboots.

# Install prerequisites
apt-get update
apt-get install software-properties-common

add-apt-repository ppa:projectatomic/ppa
apt-get update

# Install CRI-O
apt-get install cri-o-1.11

# Start CRI-O
systemctl start crio
```

4.(å¯é€‰)Containerd

```bash
# Prerequisites
modprobe overlay
modprobe br_netfilter

# Setup required sysctl params, these persist across reboots.
cat > /etc/sysctl.d/99-kubernetes-cri.conf <<EOF
net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF

sysctl --system

# Install containerd
## Set up the repository
### Install packages to allow apt to use a repository over HTTPS
apt-get update && apt-get install -y apt-transport-https ca-certificates curl software-properties-common

### Add Dockerâ€™s official GPG key
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -

### Add Docker apt repository.
add-apt-repository \
    "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
    $(lsb_release -cs) \
    stable"

## Install containerd
apt-get update && apt-get install -y containerd.io

# Configure containerd
mkdir -p /etc/containerd
containerd config default > /etc/containerd/config.toml

# Restart containerd
systemctl restart containerd

# ä½¿ç”¨systemd
systemd
To use the systemd cgroup driver, set plugins.cri.systemd_cgroup = true in /etc/containerd/config.toml. When using kubeadm, manually configure the cgroup driver for kubelet as well
```

----

## 3.å®‰è£…kubelet kubeadm kubectl

å®˜æ–¹æ¨èçš„å®‰è£…æ–¹å¼

```bash
# Install packages to allow apt to use a repository over HTTPS
apt-get update && apt-get install -y apt-transport-https curl

# Add Googleâ€™s official GPG key
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -

# Add kubernetes apt repository.
cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF
apt-get update && apt-get install -y kubelet kubeadm kubectl
apt-mark hold kubelet kubeadm kubectl
systemctl daemon-reload && systemctl restart kubelet
```

----

## 4.åˆå§‹åŒ–kubernetesé›†ç¾¤

å¯ä»¥å…ˆæŠŠæ‰€éœ€è¦çš„é•œåƒpullä¸‹æ¥ `kubeadm config images pull`

æ‰§è¡ŒæœŸé—´ä¸èƒ½ä¸­æ–­shellï¼Œä¸ç„¶é‡æ–°å¼„å¾—è¯å¾ˆå¤´ç–¼ï¼Œæœ€å¥½å…ˆå¼€ä¸ªtmux
ä½¿ç”¨kubeadm initåˆå§‹åŒ–kubernetesé›†ç¾¤ï¼Œå¯ä»¥æŒ‡å®šé…ç½®æ–‡ä»¶ï¼ŒæŠŠIPæ›¿æ¢ä¸ºè¿™å°æœºå™¨çš„å†…ç½‘IPï¼Œè¦k8s-nodeèŠ‚ç‚¹èƒ½å¤Ÿè®¿é—®å¾—åˆ°

`kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=IP`

æœ€ååˆå§‹åŒ–æˆåŠŸçš„è¯ä¼šå‡ºç°ä»¥ä¸‹ï¼Œ

```bash
[mark-control-plane] Marking the node k8s-master as control-plane by adding the label "node-role.kubernetes.io/master=''"
[mark-control-plane] Marking the node k8s-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
[bootstrap-token] Using token: i311md.mhwgl9rr3q26rc4n
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] creating the "cluster-info" ConfigMap in the "kube-public" namespace
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join IP:6443 --token i311md.mhwgl9rr3q26rc4n \
    --discovery-token-ca-cert-hash sha256:21db38130a6868b5f07be1435c5ad29c0880fea481c50005d654de06fd95db2a
```

ç„¶åæŸ¥çœ‹ä¸€ä¸‹å„ä¸ªå®¹å™¨çš„è¿è¡ŒçŠ¶æ€

```bash
â•­â”€root@k8s-master ~
â•°â”€# docker ps -a
CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS               NAMES
38d9c698ec37        efb3887b411d           "kube-controller-manâ€¦"   7 minutes ago       Up 7 minutes                            k8s_kube-controller-manager_kube-controller-manager-k8s-master_kube-system_f423ac50e24b65e6d66fe37e6d721912_0
c273979e75b6        8931473d5bdb           "kube-scheduler --biâ€¦"   7 minutes ago       Up 7 minutes                            k8s_kube-scheduler_kube-scheduler-k8s-master_kube-system_f44110a0ca540009109bfc32a7eb0baa_0
71f1f40dfa9e        cfaa4ad74c37           "kube-apiserver --adâ€¦"   7 minutes ago       Up 7 minutes                            k8s_kube-apiserver_kube-apiserver-k8s-master_kube-system_d57282173a211f69b917251534760047_0
37636f04f5d6        2c4adeb21b4f           "etcd --advertise-clâ€¦"   7 minutes ago       Up 7 minutes                            k8s_etcd_etcd-k8s-master_kube-system_dcd3914b600c5e8e86b2026688cc6dc5_0
48fc68b067de        k8s.gcr.io/pause:3.1   "/pause"                 7 minutes ago       Up 7 minutes                            k8s_POD_kube-scheduler-k8s-master_kube-system_f44110a0ca540009109bfc32a7eb0baa_0
3c9f8e8224cf        k8s.gcr.io/pause:3.1   "/pause"                 7 minutes ago       Up 7 minutes                            k8s_POD_kube-apiserver-k8s-master_kube-system_d57282173a211f69b917251534760047_0
b4903d8f18ee        k8s.gcr.io/pause:3.1   "/pause"                 7 minutes ago       Up 7 minutes                            k8s_POD_kube-controller-manager-k8s-master_kube-system_f423ac50e24b65e6d66fe37e6d721912_0
f6d2cd0b03cd        k8s.gcr.io/pause:3.1   "/pause"                 7 minutes ago       Up 7 minutes                            k8s_POD_etcd-k8s-master_kube-system_dcd3914b600c5e8e86b2026688cc6dc5_0
74a3699833bc        20a2d7035165           "/usr/local/bin/kubeâ€¦"   9 minutes ago       Up 4 seconds                            k8s_kube-proxy_kube-proxy-g4nd4_kube-system_afc4ba92-7657-11e9-b684-2aabd22d242a_1
ba61bed68ecc        k8s.gcr.io/pause:3.1   "/pause"                 9 minutes ago       Up 9 minutes                            k8s_POD_kube-proxy-g4nd4_kube-system_afc4ba92-7657-11e9-b684-2aabd22d242a_4
```

----

æˆ‘ç¬¬ä¸€æ¬¡åˆå§‹åŒ–å› ä¸ºshellä¸­æ–­å¤±è´¥äº†ğŸ˜±æŠ¥é”™

```bash
[kubelet-check] Initial timeout of 40s passed.
error execution phase upload-config/kubelet: Error writing Crisocket information for the control-plane node: timed out waiting for the condition
```

ç¬¬äºŒæ¬¡åˆå§‹åŒ–è¿˜æ˜¯å¤±è´¥ğŸ˜­

```bash
â•­â”€root@k8s-master ~
â•°â”€# kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=
[init] Using Kubernetes version: v1.14.1
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Activating the kubelet service
[certs] Using certificateDir folder "/etc/kubernetes/pki"
[certs] Generating "etcd/ca" certificate and key
[certs] Generating "etcd/server" certificate and key
[certs] etcd/server serving cert is signed for DNS names [k8s-master localhost] and IPs [IP 127.0.0.1 ::1]
[certs] Generating "etcd/peer" certificate and key
[certs] etcd/peer serving cert is signed for DNS names [k8s-master localhost] and IPs [IP 127.0.0.1 ::1]
[certs] Generating "etcd/healthcheck-client" certificate and key
[certs] Generating "apiserver-etcd-client" certificate and key
[certs] Generating "ca" certificate and key
[certs] Generating "apiserver-kubelet-client" certificate and key
[certs] Generating "apiserver" certificate and key
[certs] apiserver serving cert is signed for DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 IP]
[certs] Generating "front-proxy-ca" certificate and key
[certs] Generating "front-proxy-client" certificate and key
[certs] Generating "sa" key and public key
[kubeconfig] Using kubeconfig folder "/etc/kubernetes"
[kubeconfig] Writing "admin.conf" kubeconfig file
[kubeconfig] Writing "kubelet.conf" kubeconfig file
[kubeconfig] Writing "controller-manager.conf" kubeconfig file
[kubeconfig] Writing "scheduler.conf" kubeconfig file
[control-plane] Using manifest folder "/etc/kubernetes/manifests"
[control-plane] Creating static Pod manifest for "kube-apiserver"
[control-plane] Creating static Pod manifest for "kube-controller-manager"
[control-plane] Creating static Pod manifest for "kube-scheduler"
[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
[kubelet-check] Initial timeout of 40s passed.
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get http://localhost:10248/healthz: dial tcp 127.0.0.1:10248: connect: connection refused.
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get http://localhost:10248/healthz: dial tcp 127.0.0.1:10248: connect: connection refused.
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get http://localhost:10248/healthz: dial tcp 127.0.0.1:10248: connect: connection refused.
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get http://localhost:10248/healthz: dial tcp 127.0.0.1:10248: connect: connection refused.
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get http://localhost:10248/healthz: dial tcp 127.0.0.1:10248: connect: connection refused.

Unfortunately, an error has occurred:
        timed out waiting for the condition

This error is likely caused by:
        - The kubelet is not running
        - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)

If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands:
        - 'systemctl status kubelet'
        - 'journalctl -xeu kubelet'

Additionally, a control plane component may have crashed or exited when started by the container runtime.
To troubleshoot, list all containers using your preferred container runtimes CLI, e.g. docker.
Here is one example how you may list all Kubernetes containers running in docker:
        - 'docker ps -a | grep kube | grep -v pause'
        Once you have found the failing container, you can inspect its logs with:
        - 'docker logs CONTAINERID'
error execution phase wait-control-plane: couldn't initialize a Kubernetes cluster
```

~~å¦‚æœä½ åˆå§‹åŒ–å¤±è´¥çš„è¯ï¼Œé‚£å°±åˆ é™¤æ‰€æœ‰çš„å®¹å™¨ï¼Œåˆ é™¤/etc/kubernetes/* åˆ é™¤ /var/lib/etcd/*~~

å…¶å®è¿›è¡Œkubeadm reseté‡ç½®å†æ‰§è¡Œkubeadm initä¹Ÿè¡Œï¼Œè¿™æ ·æ›´æ–¹ä¾¿äº›ğŸ˜‚
ç„¶åå†é‡æ–°åˆå§‹åŒ– `kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=157.220.164.247`

åŠ ä¸ªå‚æ•°`--ignore-preflight-errors=all`é‡æ–°åˆå§‹åŒ–

----

## 5.å°†k8s-nodeèŠ‚ç‚¹åŠ å…¥åˆ°k8s-master

nodeèŠ‚ç‚¹ä¹Ÿæ˜¯å’ŒmasterèŠ‚ç‚¹ä¸€æ ·ï¼Œå®‰è£…dockerï¼Œkubelet kubeadm kubectlã€‚ä¸è¿‡æœ€åä¸éœ€è¦åˆå§‹åŒ–é›†ç¾¤ï¼Œä¸ç”¨kubeadm initï¼Œè€Œæ˜¯ç›´æ¥åŠ å…¥åˆ°masterå½“ä¸­æ¥ã€‚å¦‚æœmasteråˆå§‹åŒ–åæ‰¾ä¸åˆ°kubeadm joinæ‰€éœ€è¦çš„tokenï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤é‡æ–°ç”Ÿæˆä¸€ä¸ªtoken,æ³¨æ„ ttyå‚æ•°ä¸º0åˆ™è¿™ä¸ªtokenæ°¸ä¹…ä¸ä¼šå¤±æ•ˆã€‚å¯ä»¥è‡ªå®šä¹‰å¤±æ•ˆæœŸé™ã€‚

```bash
kubeadm token generate
kubeadm token create ljfmu1.5kek1jy2xdb8sopv  --print-join-command --ttl=0
kubeadm token create $(kubeadm token generate)  --print-join-command --ttl=0
```

åªéœ€è¦ä¸€ä¸ªå‘½ä»¤å°±å¯ä»¥å°† k8s-node èŠ‚ç‚¹åŠ å…¥åˆ° master çš„ç®¡ç†ä¹‹ä¸‹

`kubeadm join IP:6443 --token ljfmu1.5kek1jy2xdb8sopv --discovery-token-ca-cert-hash sha256:3b18b4cc1debc63d57e03da52424a3b3bacf03cc290b94cbe5b6aaf9c152f0cf`

åŠ å…¥æˆåŠŸåä¼šæç¤ºä»¥ä¸‹å†…å®¹ğŸ˜˜

```bash
[preflight] Running pre-flight checks
[preflight] Reading configuration from the cluster...
[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'
[kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.14" ConfigMap in the kube-system namespace
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Activating the kubelet service
[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the control-plane to see this node join the cluster.
```

æ³¨æ„: å¦‚æœhostnameå¦‚æœæ˜¯éšæœºç”Ÿæˆçš„å¸¦æœ‰`_`æ˜¯ä¸è¡Œçš„ï¼Œé‚£å°±ä½¿ç”¨ ```hostnamectl set-hostname k8s-node2 && bash```è®¾ç½®ä¸€ä¸‹ä¸‹ğŸ˜‚

```bash
name: Invalid value: "vm_158_35_centos": a DNS-1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')
```
